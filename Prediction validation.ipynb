{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import hypertools as hyp\n",
    "import time, glob, itertools\n",
    "import geoplot as gplt\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='ticks', context='talk')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'J:\\\\Geology\\\\WSGS\\\\Projects\\\\Critical Minerals\\\\probability maps\\\\'\n",
    "allFiles=glob.glob(path+\"*.csv\")\n",
    "frame=pd.DataFrame\n",
    "listed=[]\n",
    "for file in allFiles:\n",
    "    df = pd.read_csv(file, index_col=[0])\n",
    "    listed.append(df)\n",
    "frame = pd.concat(listed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "huc12=gpd.read_file(r'J:\\Geology\\WSGS\\GIS\\huc_12.shp') #reads in the hydraulic basin units and adds an area column\n",
    "huc12= huc12.to_crs({'init': 'epsg:3732'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2382"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(huc12.HUC_12.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['HUC_12']=frame.HUC_12.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaptainHucstable = huc12.merge(frame, on='HUC_12' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inHouse=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\inhouse_elemental.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import fiona\n",
    "#writes the point data to a shapefile in the dir called data.shp\n",
    "geometry = [Point(xy) for xy in zip(inHouse.longitude, inHouse.latitude)]\n",
    "crs = {'init': 'epsg:3732'} \n",
    "geo_df = GeoDataFrame(inHouse, crs={'init': 'epsg:4326'}, geometry=geometry)\n",
    "#geo_df.to_file(driver='ESRI Shapefile', filename='data.shp')\n",
    "projGeoDF=geo_df.to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_huc = gpd.sjoin(huc12, projGeoDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\validationmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_huc = val_huc.merge(validations, on='Sample_ID') #this is the inhouse data joined with the HUC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 101/101 [00:00<00:00, 4204.92it/s]\n",
      "  0%|                                                                                          | 0/101 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "true_vals = []\n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    true_vals.append(val_huc.loc[samples].HUC_12)\n",
    "\n",
    "bflat = []  \n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    formation = val_huc.loc[samples].formation[0:10]\n",
    "    b = []\n",
    "    for element in range(34,99):\n",
    "        ppm = val_huc.columns[element] #select each element in the list\n",
    "        valued = val_huc.loc[samples][element] #select each elements values \n",
    "        #from the big list, select element, formation, and concentration greater than the sample has, and create a list of the\n",
    "        #basins that we should explore\n",
    "        b0 = CaptainHucstable[(CaptainHucstable['element']== ppm) & (CaptainHucstable['formation'].str.contains(formation)) &(\n",
    "            CaptainHucstable['bins_ppm']>= valued) & (CaptainHucstable['prob']>0.6)].HUC_12.values\n",
    "        b.append(b0)\n",
    "    bflat.append(np.unique(np.asarray([item for sublist in b for item in sublist])))\n",
    "preds = np.unique(np.asarray([item for sublist in bflat for item in sublist]))\n",
    "TP = len(set(true_vals).intersection(preds))\n",
    "FP = len(preds)-len(set(true_vals).intersection(preds))\n",
    "TN = len(huc12.HUC_12.unique())-len(preds)\n",
    "FN = len(set(true_vals).intersection(set(huc12.HUC_12.unique()) ^ set(preds)))\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "acc = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([precision, recall, acc ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 2*((precision*recall)/(precision+recall))\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([TP, FP, TN, FN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.DataFrame(columns=val_huc.columns[34:-1])\n",
    "#df['Sample_ID'] = val_huc.Sample_ID\n",
    "#choices = []\n",
    "Fone = []\n",
    "\n",
    "\n",
    "\n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    a = val_huc.loc[samples].HUC_12 #select the samples huc\n",
    "    formation = val_huc.loc[samples].formation[0:10]\n",
    "    b = []\n",
    "    for element in range(34,99):\n",
    "        ppm = val_huc.columns[element] #select each element in the list\n",
    "        valued = val_huc.loc[samples][element] #select each elements values \n",
    "        #from the big list, select element, formation, and concentration greater than the sample has, and create a list of the\n",
    "        #basins that we should explore\n",
    "        b0 = CaptainHucstable[(CaptainHucstable['element']== ppm) & (CaptainHucstable['formation'].str.contains(formation)) &(\n",
    "            CaptainHucstable['bins_ppm']>= valued) & (CaptainHucstable['prob']>0.1)].HUC_12.values\n",
    "        b.append(b0)\n",
    "    bflat = np.unique(np.asarray([item for sublist in b for item in sublist]))\n",
    "\n",
    "    if a in bflat:\n",
    "        #df[ppm].iloc[samples]=1 #if the actual HUC matches the list of predicted HUC's then we record a 1\n",
    "        TP.append(1)\n",
    "        FP.append(len(b)-1)\n",
    "        TN.append(len(huc12.HUC_12.unique())-len(b))\n",
    "        FN.append(0)\n",
    "                       \n",
    "    else: \n",
    "        TP.append(0)\n",
    "        FP.append(len(b))\n",
    "        TN.append(len(huc12.HUC_12.unique())-1)\n",
    "        FN.append(1)\n",
    "            #df[ppm].iloc[samples]=0 #if they don't match we record a 0\n",
    "        #choices.append(len(b))\n",
    "    precision = np.nan_to_num(np.asarray(TP)/(np.asarray(TP)+np.asarray(FP)))\n",
    "    recall = np.asarray(TP)/(np.asarray(TP)+np.asarray(FN))\n",
    "    acc = (np.asarray(TP)+np.asarray(TN))/(np.asarray(TP)+np.asarray(TN)+np.asarray(FP)+np.asarray(FN))\n",
    "    F1 = np.nan_to_num(2*((precision*recall)/(precision+recall)))\n",
    "    Fone.append(F1)\n",
    "#df.to_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\accuracy_60percent_probability.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\accuracy_50percent_probability.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\intersection_huc12.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random sampling \n",
    "1. select in house sample HUC\n",
    "2. select in house sample formation\n",
    "3. build list of HUC's with formation\n",
    "4. randomly select HUC's and compare overlap \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(columns=val_huc.columns[34:-1])\n",
    "df2['Sample_ID'] = val_huc.Sample_ID\n",
    "\n",
    "for samples in tqdm(range(len(val_huc)-1)):\n",
    "    a = val_huc.loc[samples].HUC_12 #select the samples huc\n",
    "    formation = val_huc.loc[samples].formation[0:10]\n",
    "    for element in range(34,99):\n",
    "        ppm = val_huc.columns[element] #select each element in the list\n",
    "        try:\n",
    "            options = d2[d2['Unit_Name'].str.contains(formation)].HUC_12.values\n",
    "            print(options)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.choice(options, d2[element, samples]) #, np.round(len(options)*0.1).astype(int))   \n",
    "            if int(a) in b:\n",
    "                df2[ppm].iloc[samples]=1 #if the actual HUC matches the list of predicted HUC's then we record a 1\n",
    "            else: \n",
    "                df2[ppm].iloc[samples]=0 #if they don't match we record a 0\n",
    "        except:\n",
    "            df2[ppm].iloc[samples]=0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAccuracy = []\n",
    "for i in range(len(df)):\n",
    "    sampleAccuracy.append(df.loc[i].values[1:-1].sum()/len(df.loc[i].values[0:-1]))\n",
    "\n",
    "randomsampleAccuracy = []\n",
    "for i in range(len(df2)):\n",
    "    randomsampleAccuracy.append(df2.loc[i].values[0:-1].sum()/len(df2.loc[i].values[0:-1]))\n",
    "plt.plot(randomsampleAccuracy, label='Random')\n",
    "plt.plot(sampleAccuracy, label='Predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(randomsampleAccuracy), np.mean(sampleAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomsampleAccuracy\n",
    "randomsampleAccuracy = [i for i in randomsampleAccuracy if i > 0]\n",
    "sampleAccuracy = [i for i in sampleAccuracy if i > 0]\n",
    "\n",
    "print(np.mean(randomsampleAccuracy), np.mean(sampleAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementAccuracy = []\n",
    "for element in range(65):\n",
    "    elementAccuracy.append(df.iloc[0:,element].values.sum()/101)\n",
    "    \n",
    "randomelementAccuracy = []\n",
    "\n",
    "for element in range(65):\n",
    "    randomelementAccuracy.append(df2.iloc[0:,element].fillna(0).values.sum()/101)\n",
    "plt.plot(randomelementAccuracy, label='Random')\n",
    "plt.plot(elementAccuracy, label='Predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(randomelementAccuracy), np.mean(elementAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\accuracy_50percent_probability_huc12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision is number of correct results divided by number returned\n",
    "recall is number of correct results divided by number that should be returned\n",
    "\n",
    "so precision is 0-1 and recall will be larger than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
