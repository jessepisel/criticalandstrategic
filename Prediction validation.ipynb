{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import hypertools as hyp\n",
    "import time, glob, itertools\n",
    "import geoplot as gplt\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='ticks', context='talk')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'J:\\\\Geology\\\\WSGS\\\\Projects\\\\Critical Minerals\\\\probability maps\\\\'\n",
    "allFiles=glob.glob(path+\"*.csv\")\n",
    "frame=pd.DataFrame\n",
    "listed=[]\n",
    "for file in allFiles:\n",
    "    df = pd.read_csv(file, index_col=[0])\n",
    "    listed.append(df)\n",
    "frame = pd.concat(listed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "huc12=gpd.read_file(r'J:\\Geology\\WSGS\\GIS\\huc_12.shp') #reads in the hydraulic basin units and adds an area column\n",
    "huc12= huc12.to_crs({'init': 'epsg:3732'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2382"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(huc12.HUC_12.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['HUC_12']=frame.HUC_12.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaptainHucstable = huc12.merge(frame, on='HUC_12' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inHouse=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\inhouse_elemental.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import fiona\n",
    "#writes the point data to a shapefile in the dir called data.shp\n",
    "geometry = [Point(xy) for xy in zip(inHouse.longitude, inHouse.latitude)]\n",
    "crs = {'init': 'epsg:3732'} \n",
    "geo_df = GeoDataFrame(inHouse, crs={'init': 'epsg:4326'}, geometry=geometry)\n",
    "#geo_df.to_file(driver='ESRI Shapefile', filename='data.shp')\n",
    "projGeoDF=geo_df.to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_huc = gpd.sjoin(huc12, projGeoDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations=pd.read_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\validationmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_huc = val_huc.merge(validations, on='Sample_ID') #this is the inhouse data joined with the HUC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 101/101 [00:00<00:00, 4204.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 101/101 [2:58:47<00:00, 106.21s/it]\n"
     ]
    }
   ],
   "source": [
    "true_vals = []\n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    true_vals.append(val_huc.loc[samples].HUC_12)\n",
    "\n",
    "bflat = []  \n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    formation = val_huc.loc[samples].formation[0:10]\n",
    "    b = []\n",
    "    for element in range(34,99):\n",
    "        ppm = val_huc.columns[element] #select each element in the list\n",
    "        valued = val_huc.loc[samples][element] #select each elements values \n",
    "        #from the big list, select element, formation, and concentration greater than the sample has, and create a list of the\n",
    "        #basins that we should explore\n",
    "        b0 = CaptainHucstable[(CaptainHucstable['element']== ppm) & (CaptainHucstable['formation'].str.contains(formation)) &(\n",
    "            CaptainHucstable['bins_ppm']>= valued) & (CaptainHucstable['prob']>0.6)].HUC_12.values\n",
    "        b.append(b0)\n",
    "    bflat.append(np.unique(np.asarray([item for sublist in b for item in sublist])))\n",
    "preds = np.unique(np.asarray([item for sublist in bflat for item in sublist]))\n",
    "TP = len(set(true_vals).intersection(preds))\n",
    "FP = len(preds)-len(set(true_vals).intersection(preds))\n",
    "TN = len(huc12.HUC_12.unique())-len(preds)\n",
    "FN = len(set(true_vals).intersection(set(huc12.HUC_12.unique()) ^ set(preds)))\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "acc = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025193798449612403, 0.8125, 0.36511919698870765]\n"
     ]
    }
   ],
   "source": [
    "print([precision, recall, acc ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04887218045112781"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = 2*((precision*recall)/(precision+recall))\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 1509, 834, 9]\n"
     ]
    }
   ],
   "source": [
    "print([TP, FP, TN, FN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.DataFrame(columns=val_huc.columns[34:-1])\n",
    "#df['Sample_ID'] = val_huc.Sample_ID\n",
    "#choices = []\n",
    "Fone = []\n",
    "\n",
    "\n",
    "\n",
    "for samples in tqdm(range(len(val_huc))):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    a = val_huc.loc[samples].HUC_12 #select the samples huc\n",
    "    formation = val_huc.loc[samples].formation[0:10]\n",
    "    b = []\n",
    "    for element in range(34,99):\n",
    "        ppm = val_huc.columns[element] #select each element in the list\n",
    "        valued = val_huc.loc[samples][element] #select each elements values \n",
    "        #from the big list, select element, formation, and concentration greater than the sample has, and create a list of the\n",
    "        #basins that we should explore\n",
    "        b0 = CaptainHucstable[(CaptainHucstable['element']== ppm) & (CaptainHucstable['formation'].str.contains(formation)) &(\n",
    "            CaptainHucstable['bins_ppm']>= valued) & (CaptainHucstable['prob']>0.1)].HUC_12.values\n",
    "        b.append(b0)\n",
    "    bflat = np.unique(np.asarray([item for sublist in b for item in sublist]))\n",
    "\n",
    "    if a in bflat:\n",
    "        #df[ppm].iloc[samples]=1 #if the actual HUC matches the list of predicted HUC's then we record a 1\n",
    "        TP.append(1)\n",
    "        FP.append(len(b)-1)\n",
    "        TN.append(len(huc12.HUC_12.unique())-len(b))\n",
    "        FN.append(0)\n",
    "                       \n",
    "    else: \n",
    "        TP.append(0)\n",
    "        FP.append(len(b))\n",
    "        TN.append(len(huc12.HUC_12.unique())-1)\n",
    "        FN.append(1)\n",
    "            #df[ppm].iloc[samples]=0 #if they don't match we record a 0\n",
    "        #choices.append(len(b))\n",
    "    precision = np.nan_to_num(np.asarray(TP)/(np.asarray(TP)+np.asarray(FP)))\n",
    "    recall = np.asarray(TP)/(np.asarray(TP)+np.asarray(FN))\n",
    "    acc = (np.asarray(TP)+np.asarray(TN))/(np.asarray(TP)+np.asarray(TN)+np.asarray(FP)+np.asarray(FN))\n",
    "    F1 = np.nan_to_num(2*((precision*recall)/(precision+recall)))\n",
    "    Fone.append(F1)\n",
    "#df.to_csv(r'J:\\Geology\\WSGS\\Projects\\Critical Minerals\\accuracy_60percent_probability.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Publication', 'Sample_ID', 'Old_Sample_ID', 'WyoDoG', 'WyoDoG_Name',\n",
       "       'Sample_Desc', 'latitude', 'longitude', 'ag_ppm', 'al_pct', 'as_ppm',\n",
       "       'au_ppm', 'ba_ppm', 'be_ppm', 'bi_ppm', 'ca_pct', 'cd_ppm', 'cd_ppm.1',\n",
       "       'co_ppm', 'cr_ppm', 'cs_ppm', 'cu_ppm', 'dy_ppm', 'er_ppm', 'eu_ppm',\n",
       "       'fe_pct', 'ga_ppm', 'gd_ppm', 'ge_ppm', 'hf_ppm', 'hg_ppm', 'ho_ppm',\n",
       "       'in_ppm', 'k_pct', 'la_ppm', 'li_ppm', 'lu_ppm', 'mg_pct', 'mn_ppm',\n",
       "       'mo_ppm', 'na_pct', 'nb_ppm', 'nd_ppm', 'ni_ppm', 'p_ppm', 'pb_ppm',\n",
       "       'pd_ppm', 'pr_ppm', 'pt_ppm', 'rb_ppm', 're_ppm', 's_pct', 'sb_ppm',\n",
       "       'sc_ppm', 'se_ppm', 'sm_ppm', 'sn_ppm', 'sr_ppm', 'ta_ppm', 'tb_ppm',\n",
       "       'te_ppm', 'th_ppm', 'ti_ppm1', 'ti_pct', 'ti_ppm', 'tm_ppm', 'u_ppm',\n",
       "       'v_ppm', 'w_ppm', 'y_ppm', 'yb_ppm', 'zn_ppm', 'zr_ppm', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inHouse.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
